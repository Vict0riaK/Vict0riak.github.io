---
layout: post
title: Reflection Essay
subtitle: 
categories: Essex Deciphering Big Data Module
tags: [Big, data]
---

## Reflection Essay

For this reflection I am going to follow Rolfe’s model of reflection (Rolfe, 2001) of what, so what and now what chapters for each experience. The module started with introduction to Big Data in the lecture by prof. Godfried Williams, its challenges and methods/techniques to address those. Although I have indeed heard about Big Data earlier, I was not aware which strategies are useful to extract value out of it. I found the content important since it covers the dimensions of Big Data: Volume, Variety, Veracity, and Velocity (Ohlhorst, 2013). Going through Olhhorst’s book “Turning Big data into Big Money” I have learned the real life value of big data which companies like Facebook, Amazon and Google did turn into big money (Ohlhorst, 2013). This is truly inspiring, and I can imagine that for many other businesses as well and their goal would be to turn data into real value. Going forward I will read the book cited in references on data wrangling with Python since I believe it is a good start for the Data Science professional. I would love to help companies to use Big Data Analytics to be more successful and prosperous. 
In the second lecture by prof Williams, we looked at different levels of data structures and formats of data that can be read by machines. I have learned that XML, JSON and CSV formats convert unstructured data to structured and enable standardization. I could engage deeper with the content of this lecture due to my own experience in web scraping. I participated in hackathon a couple of years ago where we used Twitter API as well as Beautiful Soup. Apart from online sources for data extraction, we have learned the offline possible sources and importance of fact finding and verification. The quality of the data plays an important role for obtaining correct results so reporting errors, handling missing data and using good sources is crucial. 
After going through the main concepts of Big Data topic we worked in groups to create logical solution as a team of consultants. When it comes to working in teams, learning from each other is the part that I enjoy the most. The motivation is higher, and experience is richer when you learn from your peers as well. Luckily my partner and I reside in Germany so not only we worked online but also managed to meet in person. We have created a logical database for the company my team member works for. I didn’t know much about the market of electric vehicles in Europe and how the infrastructure is catching up. To write individual reflection, I have researched the topic even more extensively and gained a deeper understanding of car manufacturing in Germany. We have designed a relational database, and its goal was to capture unstructured data from mobile applications, charging stations and electricity providers, analyze it and provide valuable insights to the Board on station utilization, levels of utilization for various charging points to optimize the business and anticipate growth and locations to build charging points promptly. I was responsible for ERD diagram along with description of items and their attributes. Together we worked out the Primary and Secondary keys. Although it was a good effort and we have learned a lot, indeed upon reflection in my individual assignment I have improved the design a bit by adding necessary tables like users to ensure security and feedback to learn about customer experiences. We have chosen the relational database due to the nature of our data and the connections between items. The PostgreSQL was the technical solution since it met all the necessary requirements. After teamwork we had to evaluate each other using provided template. 
The feedback provided by the professor Williams emphasized importance of considering non-functional requirements and we were asked to expand on legal and compliance matters further. My biggest challenge writing individual assignment was that I am not very familiar with the use-case and possible scenarios that can happen, so it is very difficult for me to anticipate them since I am out of context. I tried to learn as much as I could about the topic from the perspective of the entrepreneur to anticipate legal and compliance topics in this industry. 
Working as a team was extremely valuable to feel more connected with the cohort. Although our team was small but before we divided into teams we connected informally and tried to find solution that works best for all. To fully embraced the experience, I have developed the tested our solution in PostgreSQL and surprisingly it went very smoothly although it was my first experience. The queries also worked, and I populated random data and pulled reports I think would be valuable for the management team. Unfortunately, I could not test data wrangling in real case scenario, but I hope to gain some experience as a professional going forward. 
After teamwork, we went for prof Williams through Dream Home case study, and I have learned the importance of relational databases and their history. It was great to analyse together wrangling problems and appropriate techniques for Dream Home case study. We focused on importance of mission, iterative approach to finding solutions, interaction with different teams, etc. In individual assignment I followed the same logic for designing reports – putting the mission statement at the core so that I can provide valuable insights from collected data. During the lecture not only, we explored the real-life scenario of Dream house, but also discussed our own cases and prof. Williams guided our thinking by asking questions on hypothetical scenarios that we didn’t think of. This was insightful – first I learned in depth on what other students were working, presented our solution and learned not only about things we might have missed but same for rest of the teams. 
Going forward as a professional I will use company goal and mission statement to guide the design of technical solutions and define requirements for the same. For example, concurrency requirement would affect the speed of response and distributed solution. These are strategic questions and are the cornerstone of success. Extracting value from the big data should serve the quality decisions which are only possible if data is of a good quality. 

Ohlhorst, F. (2013). Big data analytics: Turning big data into big money [Electronic resource]. John Wiley & Sons. https://books.google.de/books?hl=en&lr=&id=59jqanSN0mwC&oi=fnd&pg=PR9&dq=ohlorst+2012&ots=_H5KGPGGW7&sig=YJKfPLdEutF1gHse4PTW29FJSCk&redir_esc=y#v=onepage&q=ohlorst%202012&f=false [accessed 26.01.2025]
Rolfe, G. et. al. (2001). Critical reflection in nursing and the helping professions: A user’s guide. Palgrave Macmillan.




